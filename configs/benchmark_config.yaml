# Production Benchmark Configuration

# Model configurations
models:
  gemma-2b:
    type: gemma
    size: 2b
    variant: it
    cache_dir: cache/models
    quantization: true
  
  gemma-9b:
    type: gemma
    size: 9b
    variant: it
    cache_dir: cache/models
    quantization: true

# Task configurations
tasks:
  mmlu:
    type: mmlu
    subset: all  # Can be "all" or specific subject like "mathematics"
    shot_count: 5
  
  efficiency:
    type: efficiency
    sample_prompts:
      - "Explain the theory of relativity"
      - "Write a short story about a robot who discovers emotions"
      - "Summarize the key events of World War II"
      - "Describe the process of photosynthesis in plants"
    output_lengths: [128, 256, 512, 1024]

# Output configuration
output:
  path: results
  visualize: true
  dashboard: false

# Hardware configuration
hardware:
  device: auto  # auto, cuda, cpu, mps
  precision: bfloat16  # bfloat16, float16, float32
  quantization: true