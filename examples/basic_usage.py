#!/usr/bin/env python3
"""
Basic usage example for the Gemma Benchmarking Suite.

This script demonstrates how to:
1. Set up authentication
2. Run a simple benchmark
3. Generate visualizations
4. Access results
"""

import os
import sys
import logging
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from gemma_benchmark.auth import setup_huggingface_auth
from gemma_benchmark.core.benchmark import GemmaBenchmark
from gemma_benchmark.visualization.charts import ChartGenerator


def setup_logging():
    """Set up logging for the example."""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )


def main():
    """Run basic benchmark example."""
    setup_logging()
    logger = logging.getLogger("examples.basic_usage")
    
    logger.info("üöÄ Starting Gemma Benchmark Example")
    
    # 1. Authentication Setup
    logger.info("Setting up HuggingFace authentication...")
    if not setup_huggingface_auth():
        logger.error("Authentication failed. Please set up your HF_TOKEN.")
        return
    
    # 2. Create a simple configuration
    config_path = "examples/simple_config.yaml"
    if not os.path.exists(config_path):
        logger.info("Creating example configuration...")
        create_example_config(config_path)
    
    # 3. Initialize benchmark
    logger.info("Initializing benchmark...")
    try:
        benchmark = GemmaBenchmark(config_path)
        
        # 4. Load models and tasks
        logger.info("Loading models...")
        benchmark.load_models(["gemma-2b"])  # Start with smallest model
        
        logger.info("Loading tasks...")
        benchmark.load_tasks(["efficiency"])  # Start with quick task
        
        # 5. Run benchmarks
        logger.info("Running benchmarks...")
        results = benchmark.run_benchmarks()
        
        # 6. Save results
        logger.info("Saving results...")
        results_path = benchmark.save_results("examples/results.yaml")
        logger.info(f"Results saved to: {results_path}")
        
        # 7. Generate visualizations
        logger.info("Generating visualizations...")
        output_dir = os.path.dirname(results_path)
        chart_generator = ChartGenerator(os.path.join(output_dir, "charts"))
        
        # Create efficiency charts
        efficiency_charts = chart_generator.create_efficiency_comparison_chart(results)
        for chart_type, path in efficiency_charts.items():
            logger.info(f"Generated {chart_type} chart: {path}")
        
        # 8. Display summary
        display_results_summary(results)
        
        logger.info("‚úÖ Benchmark completed successfully!")
        
    except Exception as e:
        logger.error(f"‚ùå Benchmark failed: {e}")
        raise


def create_example_config(config_path: str):
    """Create a simple configuration file for the example."""
    import yaml
    
    config = {
        "models": {
            "gemma-2b": {
                "type": "gemma",
                "size": "2b",
                "variant": "it",
                "cache_dir": "cache/models",
                "quantization": True
            }
        },
        "tasks": {
            "efficiency": {
                "type": "efficiency",
                "sample_prompts": [
                    "Explain quantum computing in simple terms",
                    "Write a haiku about artificial intelligence",
                    "Summarize the benefits of renewable energy"
                ],
                "output_lengths": [64, 128, 256]
            }
        },
        "output": {
            "path": "examples/results",
            "visualize": True
        },
        "hardware": {
            "device": "auto",
            "precision": "bfloat16",
            "quantization": True
        }
    }
    
    os.makedirs(os.path.dirname(config_path), exist_ok=True)
    with open(config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)


def display_results_summary(results):
    """Display a summary of the benchmark results."""
    logger = logging.getLogger("examples.basic_usage")
    
    logger.info("\n" + "="*50)
    logger.info("BENCHMARK RESULTS SUMMARY")
    logger.info("="*50)
    
    for model_name, model_results in results.items():
        logger.info(f"\nüìä Model: {model_name}")
        
        for task_name, task_results in model_results.items():
            logger.info(f"  üéØ Task: {task_name}")
            
            if task_name == "efficiency":
                # Display efficiency metrics
                if "tokens_per_second" in task_results:
                    logger.info("    ‚ö° Performance:")
                    for length, tps in task_results["tokens_per_second"].items():
                        logger.info(f"      {length}: {tps:.2f} tokens/sec")
                
                if "latency" in task_results:
                    logger.info("    ‚è±Ô∏è  Latency:")
                    for length, latency in task_results["latency"].items():
                        logger.info(f"      {length}: {latency:.3f} seconds")
                        
                if "system_info" in task_results:
                    sys_info = task_results["system_info"]
                    logger.info(f"    üíª System: {sys_info.get('os', 'Unknown')} | "
                              f"CPU: {sys_info.get('cpu_count', 'Unknown')} cores | "
                              f"RAM: {sys_info.get('memory_total', 'Unknown'):.1f}GB")
                    
                    if sys_info.get("cuda_available"):
                        gpu_info = sys_info.get("gpu_name", ["Unknown"])
                        logger.info(f"    üöÄ GPU: {gpu_info[0] if gpu_info else 'Unknown'}")
                        
            else:
                # Display accuracy metrics
                if "overall" in task_results and "accuracy" in task_results["overall"]:
                    accuracy = task_results["overall"]["accuracy"]
                    logger.info(f"    üìà Accuracy: {accuracy:.4f}")


if __name__ == "__main__":
    main()
